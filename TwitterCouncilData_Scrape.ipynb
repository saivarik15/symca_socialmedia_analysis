{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from getpass import getpass\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Replace with your Twitter login credentials\n",
    "username = \"username\"\n",
    "password = \"Password\"\n",
    "organisationname = \"Essex_CC\"\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get(\"https://twitter.com/\"+organisationname)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(2)\n",
    "\n",
    "# Find the username and password input fields and fill them\n",
    "username_input = driver.find_element(By.NAME, \"text\")\n",
    "username_input.send_keys(username)\n",
    "\n",
    "# Wait for the \"Next\" button to be clickable\n",
    "next_button = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//span[contains(text(), \"Next\")]'))\n",
    ")\n",
    "next_button.click()\n",
    "\n",
    "# Wait for the page to load\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, \"password\")))\n",
    "\n",
    "# Find the password input field by its name attribute and fill it with the password\n",
    "password_input = driver.find_element(By.NAME,\"password\")\n",
    "password_input.send_keys(password)\n",
    "\n",
    "login_button = driver.find_element(By.CSS_SELECTOR, '[data-testid=\"LoginForm_Login_Button\"]')\n",
    "login_button.click()\n",
    "\n",
    "# Wait for the login process to complete\n",
    "time.sleep(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_data(tweet):\n",
    "   user = tweet.find_element(By.XPATH,'.//div[@data-testid=\"User-Name\"]//span').text\n",
    "   tweet_handle = tweet.find_element(By.XPATH,'.//div[@dir=\"ltr\"]//span[contains(text(),\"@\")]').text\n",
    "   try:\n",
    "      tweet_time = tweet.find_element(By.XPATH,'.//time').get_attribute('datetime')\n",
    "   except NoSuchElementException:\n",
    "      return\n",
    "   comment = tweet.find_element(By.XPATH, './/div[1]/div[1]/div[2]/div[2]/div[2]').text\n",
    "   response = tweet.find_element(By.XPATH, './/div[1]/div[1]/div[2]/div[2]/div[3]').text\n",
    "   text = comment + response\n",
    "   reply_cnt = tweet.find_element(By.XPATH, './/div[1]/div[1]/div[2]/div[2]//div[@data-testid=\"reply\"]').text\n",
    "   retweet_cnt = tweet.find_element(By.XPATH, './/div[1]/div[1]/div[2]/div[2]//div[@data-testid=\"retweet\"]').text\n",
    "   like_cnt = tweet.find_element(By.XPATH, './/div[1]/div[1]/div[2]/div[2]//div[@data-testid=\"like\"]').text\n",
    "\n",
    "   tweet_data = (user,tweet_handle,tweet_time,text,reply_cnt,retweet_cnt,like_cnt)\n",
    "   return tweet_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "tweet_ids = set()\n",
    "last_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "scrolling = True\n",
    "\n",
    "while scrolling:\n",
    "    page_cards = driver.find_elements(By.XPATH,'//article[@data-testid=\"tweet\"]')\n",
    "    for card in page_cards[3:]:\n",
    "        tweet = get_tweet_data(card)\n",
    "        if tweet:\n",
    "            tweet_id = ''.join(tweet)\n",
    "            if tweet_id not in tweet_ids:\n",
    "                print(\"printing tweet id: \",tweet_id)\n",
    "                tweet_ids.add(tweet_id)\n",
    "                data.append(tweet)\n",
    "                print(data)\n",
    "            \n",
    "    scroll_attempt = 0\n",
    "    while True:\n",
    "        # check scroll position\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        sleep(3)\n",
    "        curr_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "        if last_position == curr_position:\n",
    "            scroll_attempt += 1\n",
    "            \n",
    "            # end of scroll region\n",
    "            if scroll_attempt >= 3:\n",
    "                scrolling = False\n",
    "                break\n",
    "            else:\n",
    "                sleep(3) # attempt another scroll\n",
    "        else:\n",
    "            last_position = curr_position\n",
    "            break\n",
    "\n",
    "# close the web driver\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('EssexCountyCouncilData.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write the header row\n",
    "    header = ['UserName', 'Handle', 'Date_Time', 'Tweet', 'Reply', 'Retweet', 'Likes']\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    # Iterate over the data\n",
    "    for item in data:\n",
    "        # Replace newline characters with spaces in the tweet text\n",
    "        cleaned_tweet = item[3].replace('\\n', ' ')\n",
    "        \n",
    "        # Write the cleaned tweet data to the CSV file\n",
    "        writer.writerow([\n",
    "            item[0],  # UserName\n",
    "            item[1],  # Handle\n",
    "            item[2],  # Date_Time\n",
    "            cleaned_tweet,  # Tweet\n",
    "            item[4],  # Reply\n",
    "            item[5],  # Retweet\n",
    "            item[6]   # Likes\n",
    "        ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
